{
  "questions": [
    {
      "question": "What is the difference between supervised and unsupervised learning?",
      "answer": "Supervised learning involves training a model on labeled data, where each input has a corresponding output label. The model learns to map inputs to outputs. Unsupervised learning, on the other hand, deals with unlabeled data, and the model tries to find hidden patterns or intrinsic structures within the data.",
      "difficulty": "easy"
    },
    {
      "question": "Explain the concept of overfitting in machine learning.",
      "answer": "Overfitting occurs when a machine learning model learns not only the underlying patterns in the training data but also the noise and outliers, leading to poor generalization on unseen data. It can be mitigated using techniques like cross-validation, regularization, and pruning.",
      "difficulty": "easy"
    },
    {
      "question": "What is the purpose of activation functions in neural networks?",
      "answer": "Activation functions introduce non-linearity into a neural network, enabling it to learn and model complex data patterns. Common activation functions include ReLU, sigmoid, and tanh.",
      "difficulty": "easy"
    },
    {
      "question": "Describe the vanishing gradient problem in deep learning.",
      "answer": "The vanishing gradient problem occurs when gradients become too small during backpropagation, causing the weights in the earlier layers of the network to update minimally. This issue often arises with activation functions like sigmoid or tanh and can be addressed using techniques such as ReLU activation or batch normalization.",
      "difficulty": "medium"
    },
    {
      "question": "What are the key differences between Batch Gradient Descent, Stochastic Gradient Descent, and Mini-Batch Gradient Descent?",
      "answer": "Batch Gradient Descent computes the gradient of the cost function using the entire dataset, which can be computationally expensive but provides a stable convergence. Stochastic Gradient Descent updates weights after each training example, making it faster but more volatile. Mini-Batch Gradient Descent strikes a balance by updating weights using small batches of data, combining the efficiency of both methods.",
      "difficulty": "medium"
    },
    {
      "question": "What is a confusion matrix, and how is it used?",
      "answer": "A confusion matrix is a table used to evaluate the performance of a classification model by showing the actual versus predicted classifications. It includes metrics like True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives (FN), which help calculate evaluation metrics such as accuracy, precision, recall, and F1-score.",
      "difficulty": "easy"
    },
    {
      "question": "Explain Transfer Learning and its benefits in deep learning.",
      "answer": "Transfer Learning involves leveraging a pre-trained model (trained on a large dataset) for a similar task, often by fine-tuning the model on a smaller, task-specific dataset. It reduces training time, requires less data, and can improve model performance, especially in scenarios with limited labeled data.",
      "difficulty": "medium"
    },
    {
      "question": "What are the differences between CNNs and RNNs?",
      "answer": "Convolutional Neural Networks (CNNs) are primarily used for spatial data like images and focus on feature extraction using convolutional layers. Recurrent Neural Networks (RNNs) are designed for sequential data like time series or text, leveraging their ability to maintain information from previous steps in the sequence using hidden states.",
      "difficulty": "medium"
    },
    {
      "question": "What is the Curse of Dimensionality, and how can it be addressed?",
      "answer": "The Curse of Dimensionality refers to the phenomenon where the performance of a machine learning model degrades as the number of features increases, due to sparsity and increased computational complexity. It can be mitigated through dimensionality reduction techniques like PCA, feature selection, or regularization.",
      "difficulty": "medium"
    },
    {
      "question": "Explain the difference between precision and recall.",
      "answer": "Precision measures the proportion of true positive predictions among all positive predictions, while recall measures the proportion of true positive predictions among all actual positives. In essence, precision focuses on the correctness of positive predictions, and recall focuses on capturing all actual positives.",
      "difficulty": "easy"
    },
    {
      "question": "What are the key steps in a machine learning pipeline?",
      "answer": "A typical machine learning pipeline includes data collection, data preprocessing (cleaning, normalization, etc.), feature engineering, model selection, training, hyperparameter tuning, evaluation, and deployment.",
      "difficulty": "easy"
    },
    {
      "question": "How does backpropagation work in neural networks?",
      "answer": "Backpropagation is a training algorithm for neural networks that involves calculating the gradient of the loss function with respect to each weight by the chain rule. It propagates the error backward from the output layer to the input layer, allowing the weights to be updated using gradient descent.",
      "difficulty": "medium"
    },
    {
      "question": "What are GANs, and how do they work?",
      "answer": "Generative Adversarial Networks (GANs) consist of two neural networks: a generator that creates synthetic data and a discriminator that evaluates its authenticity. The two networks compete in a game-like setup, with the generator improving to create realistic data and the discriminator improving to detect fakes.",
      "difficulty": "hard"
    },
    {
      "question": "What is Reinforcement Learning?",
      "answer": "Reinforcement Learning is a type of machine learning where an agent learns to make decisions by performing actions in an environment to maximize cumulative rewards. It uses concepts like states, actions, rewards, and policies.",
      "difficulty": "medium"
    },
    {
      "question": "Describe the architecture of the Transformer model.",
      "answer": "The Transformer model consists of an encoder-decoder architecture. The encoder processes the input sequence, generating key-value pairs and embeddings, while the decoder uses these along with self-attention and cross-attention mechanisms to generate the output sequence. The model relies heavily on multi-head attention and positional encoding.",
      "difficulty": "hard"
    },
    {
      "question": "Explain the difference between L1 and L2 regularization.",
      "answer": "L1 regularization adds the absolute values of coefficients as a penalty term to the loss function, encouraging sparsity in the model. L2 regularization adds the squared values of coefficients, discouraging extreme values but not necessarily leading to sparsity.",
      "difficulty": "medium"
    },
    {
      "question": "What is dropout in neural networks, and why is it used?",
      "answer": "Dropout is a regularization technique where randomly selected neurons are ignored during training, reducing the risk of overfitting and improving the generalization of the model.",
      "difficulty": "medium"
    },
    {
      "question": "What is a Boltzmann Machine?",
      "answer": "A Boltzmann Machine is a type of stochastic neural network that learns probability distributions over its set of inputs. It is primarily used for tasks like dimensionality reduction and feature learning.",
      "difficulty": "hard"
    },
    {
      "question": "What is the role of embeddings in Natural Language Processing (NLP)?",
      "answer": "Embeddings are dense vector representations of words or phrases that capture semantic meaning. They are used in NLP tasks to improve performance and represent textual data in a way that is understandable by machine learning models.",
      "difficulty": "medium"
    },
    {
      "question": "What is beam search in sequence generation tasks?",
      "answer": "Beam search is a heuristic search algorithm used in sequence generation tasks (like machine translation) to find the most likely sequence of outputs. It expands only the top-k most probable paths at each step, balancing computational efficiency and accuracy.",
      "difficulty": "hard"
    },
    {
      "question": "Explain the concept of an attention mechanism in deep learning.",
      "answer": "Attention mechanisms allow models to focus on specific parts of input sequences when generating outputs. This improves performance in tasks like translation or summarization by dynamically weighing the importance of different input elements.",
      "difficulty": "medium"
    },
    {
      "question": "What is the difference between online and batch learning?",
      "answer": "Online learning updates the model incrementally as new data becomes available, making it suitable for streaming data. Batch learning trains the model on the entire dataset at once, which can be computationally expensive but often leads to better convergence.",
      "difficulty": "medium"
    },
    {
      "question": "How do you evaluate the performance of clustering algorithms?",
      "answer": "Clustering algorithms are evaluated using metrics like Silhouette Score, Davies-Bouldin Index, and Calinski-Harabasz Index. These metrics measure aspects such as compactness and separation between clusters.",
      "difficulty": "medium"
    },
    {
      "question": "What is the role of the softmax function in neural networks?",
      "answer": "The softmax function is used in the output layer of a neural network for multi-class classification. It converts raw logits into probabilities by exponentiating them and normalizing by the sum of all exponentiated values.",
      "difficulty": "easy"
    },
    {
      "question": "What are the differences between generative and discriminative models?",
      "answer": "Generative models, like GANs or Naive Bayes, model the joint probability distribution P(X, Y) to generate data or predict labels. Discriminative models, like SVM or logistic regression, model the conditional probability P(Y|X) and focus only on classification.",
      "difficulty": "medium"
    },
    {
      "question": "Explain how reinforcement learning differs from supervised learning.",
      "answer": "Reinforcement learning involves learning from interactions with an environment to maximize cumulative rewards, without explicit input-output pairs. Supervised learning requires labeled data to learn a mapping from inputs to outputs.",
      "difficulty": "medium"
   },
    {
      "question": "How do you choose the right evaluation metric for a classification problem?",
      "answer": "Choosing the right metric depends on the specific objectives and the nature of the data. For balanced datasets, accuracy might suffice. For imbalanced datasets, precision, recall, F1-score, or AUC-ROC are more informative as they consider false positives and false negatives.",
      "difficulty": "easy"
    },
    {
      "question": "What are word embeddings like Word2Vec and GloVe, and how do they differ?",
      "answer": "Word2Vec is a shallow neural network model that learns word embeddings based on the context of words in a corpus, using techniques like CBOW or Skip-Gram. GloVe, on the other hand, generates embeddings by factorizing a co-occurrence matrix, capturing global statistical information. While Word2Vec is focused on local context, GloVe emphasizes global co-occurrence relationships.",
      "difficulty": "medium"
    },
    {
      "question": "What is cross-validation, and why is it important?",
      "answer": "Cross-validation is a technique for assessing the performance of a model by dividing the data into training and testing sets multiple times. It helps detect overfitting and provides a more reliable estimate of model performance compared to a single train-test split.",
      "difficulty": "easy"
    },
    {
      "question": "What is the difference between feature selection and feature extraction?",
      "answer": "Feature selection involves selecting a subset of relevant features from the original dataset, while feature extraction creates new features by transforming the original features, such as using PCA to reduce dimensionality. Feature selection retains existing features, whereas feature extraction creates new ones.",
      "difficulty": "medium"
    }
    ]
}


